{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.datasets import co2\n",
    "from datadata import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from prevision import Options,XGBOOST_TYPE,addDates\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales=pd.read_csv(\"prevision/data/daily_sales.csv\",parse_dates=['Date'] ,index_col='Date').rename_axis('date')\n",
    "df_meteo=pd.read_csv(\"prevision/data/meteo.csv\",parse_dates=['time'],index_col='time').rename_axis('date').drop('Unnamed: 0',axis=1)\n",
    "df_predictHQ=pd.read_csv(\"prevision/data/affluence.csv\",parse_dates=['date'],index_col='date')\n",
    "df_all=pd.merge(pd.merge(df_sales, df_meteo, on='date'), df_predictHQ, on='date').reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=addDates(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['date'].apply(date2day)\n",
    "# hot encode day\n",
    "df = pd.get_dummies(df, columns=['day'])\n",
    "\n",
    "# Vacances\n",
    "# On ajoute une colonne\n",
    "df['vacance'] = df['date'].apply(date2vacances)\n",
    "\n",
    "# Jours fériés\n",
    "# On ajoute une colonne\n",
    "df['ferie'] = df['date'].apply(date2jourferie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_non_zero = df_all['vente'].replace(0, np.nan).dropna()\n",
    "log_sales = np.log(sales_data_non_zero)\n",
    "stl = STL(log_sales, seasonal=13,period=30*6)\n",
    "result = stl.fit()\n",
    "\n",
    "trend = result.trend\n",
    "seasonal = result.seasonal\n",
    "residual = result.resid\n",
    "# Access the components: trend, seasonal, and residual\n",
    "trend = result.trend\n",
    "seasonal = result.seasonal\n",
    "residual = result.resid\n",
    "\n",
    "# Plot the original time series and the components\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(df_sales['vente'], label='Original Time Series')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(seasonal, label='Seasonal')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(residual, label='Residual')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_based_on_duration(data, duration_months):\n",
    "    last_date = data['date'].max()\n",
    "    cutoff_date = last_date - pd.DateOffset(months=duration_months)\n",
    "    train_data = data[data['date'] <= cutoff_date]\n",
    "    validation_data = data[data['date'] > cutoff_date]\n",
    "    return train_data, validation_data\n",
    "\n",
    "def getX(x):\n",
    "    return x.drop(['date','vente'],axis=1).values\n",
    "def getY(y):\n",
    "    return y['vente'].values\n",
    "\n",
    "def plot_eval_result(eval_results):\n",
    "    # Extract training and validation losses\n",
    "    train_loss = eval_results['validation_0']['rmse']\n",
    "    val_loss = eval_results['validation_1']['rmse']\n",
    "\n",
    "    # Plot the loss\n",
    "    epochs = len(train_loss)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), train_loss, label='Train Loss')\n",
    "    plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "sales_data=df_all\n",
    "train_data_1yr, validation_data_1yr = split_data_based_on_duration(sales_data, 12)\n",
    "train_data_6mo, validation_data_6mo = split_data_based_on_duration(sales_data, 6)\n",
    "train_data_3mo, validation_data_3mo = split_data_based_on_duration(sales_data, 3)\n",
    "\n",
    "train_data_1yr.reset_index(drop=True, inplace=True)\n",
    "validation_data_1yr.reset_index(drop=True, inplace=True)\n",
    "train_data_6mo.reset_index(drop=True, inplace=True)\n",
    "validation_data_6mo.reset_index(drop=True, inplace=True)\n",
    "train_data_3mo.reset_index(drop=True, inplace=True)\n",
    "validation_data_3mo.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train=getX(train_data_3mo),getY(train_data_3mo)\n",
    "X_test,Y_test=getX(validation_data_3mo),getY(validation_data_3mo)\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': np.arange(50, 300, 50),  # Number of boosting rounds\n",
    "    'max_depth': np.arange(3, 10),  # Maximum depth of the tree\n",
    "    'learning_rate': np.arange(0.05, 0.31, 0.05),  # Learning rate\n",
    "    'subsample': np.arange(0.7, 1.0, 0.1),  # Subsample ratio\n",
    "    'colsample_bytree': np.arange(0.7, 1.0, 0.1),  # Subsample ratio of columns\n",
    "}\n",
    "xgb_regressor = xgb.XGBRegressor(random_state=42)\n",
    "random_search = RandomizedSearchCV(xgb_regressor, param_distributions=param_space,\n",
    "                                   n_iter=50, scoring='neg_mean_squared_error', cv=3,\n",
    "                                   random_state=42, verbose=1, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, Y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "val_preds = best_model.predict(X_test)\n",
    "val_rmse = np.sqrt(mean_squared_error(Y_test, val_preds))\n",
    "print('Validation RMSE:', val_rmse)\n",
    "print('best params\\n',*random_search.best_params_)\n",
    "\n",
    "best_model.fit(X_train, Y_train,\n",
    "               eval_set=[(X_train, Y_train), (X_test, Y_test)],\n",
    "               eval_metric='rmse',\n",
    "               verbose=0)\n",
    "eval_results = best_model.evals_result()\n",
    "res = best_model.predict(X_test)\n",
    "plot_eval_result(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test,label='réel')\n",
    "plt.plot(res,label='prediction')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
